{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特点\n",
    "（1）通过实现Classifier/SklearnClassifier接口（SklearnClassifier是Classifier的子类），可以方便将分类器扩展到Sklearn,Keras等其他开源工具；  \n",
    "（2）可以构建很深，很复杂的stacking结构  \n",
    "\n",
    "接下来，我在手写数值识别上演示api使用示例：  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stacking_classifier import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "X, y = digits['data'], digits['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一.基本分类器的使用\n",
    "这里所有的分类器都需要实现Classifier类的接口，如果你是使用的Sklearn风格的分类器，只需要做如下操作即可，这里默认封装了SVMClassifier,RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier,BaggingClassifier,LogisticRegression,NaiveBayesClassifier等分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoostClassifier(SklearnClassifier):\n",
    "    def __init__(self, train_params=None):\n",
    "        from sklearn.ensemble import AdaBoostClassifier\n",
    "        SklearnClassifier.__init__(self, train_params, AdaBoostClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16511852016226553\n"
     ]
    }
   ],
   "source": [
    "classifier = AdaBoostClassifier()\n",
    "classifier.build_model()\n",
    "classifier.fit(X_train, y_train)\n",
    "p_test = classifier.predict(X_test)\n",
    "print(f1_score(y_test, p_test, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二.KFolds_Classifier_Training_Wrapper包装器的使用\n",
    "```KFolds_Classifier_Training_Wrapper```可以将数据切分成```k_fold```份，并训练```k_fold```个分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9275689728048707\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "classifier = KFolds_Classifier_Training_Wrapper(classifier,k_fold=5)#这里封装一下即可，默认k_fold=5\n",
    "classifier.build_model()\n",
    "classifier.fit(X_train, y_train)\n",
    "p_test = classifier.predict(X_test)\n",
    "print(f1_score(y_test, p_test, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9361513960332069\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "#KFolds_Classifier_Training_Wrapper也可以嵌套封装，这样下面就有25个基分类器\n",
    "classifier = KFolds_Classifier_Training_Wrapper(KFolds_Classifier_Training_Wrapper(classifier))\n",
    "classifier.build_model()\n",
    "classifier.fit(X_train, y_train)\n",
    "p_test = classifier.predict(X_test)\n",
    "print(f1_score(y_test, p_test, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三.StackingClassifier分类器的使用\n",
    "```StackingClassifier```中的基分类器和元分类器可以是任意实现了Classifier，由于```KFolds_Classifier_Training_Wrapper```以及```StackingClassifier```都继承了```Classifier```接口，所以意味着你可以任意嵌套..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9111383714411929\n"
     ]
    }
   ],
   "source": [
    "classifier = StackingClassifier(\n",
    "    base_classifiers=[\n",
    "        RandomForestClassifier(),\n",
    "        AdaBoostClassifier(),\n",
    "        BaggingClassifier(),\n",
    "        SVMClassifier(),\n",
    "    ],\n",
    "    meta_classifier=LogisticRegression(),\n",
    "    force_cv=False#默认为True,会对base_classifiers，meta_classifier进行KFolds_Classifier_Training_Wrapper包装\n",
    ")\n",
    "classifier.build_model()\n",
    "classifier.fit(train_x=X_train, train_y=y_train)\n",
    "p_test = classifier.predict(X_test)\n",
    "print(f1_score(y_test, p_test, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9582916621008432\n"
     ]
    }
   ],
   "source": [
    "classifier = StackingClassifier(\n",
    "    base_classifiers=[\n",
    "        RandomForestClassifier(),\n",
    "        AdaBoostClassifier(),\n",
    "        BaggingClassifier(),\n",
    "        SVMClassifier(),\n",
    "        StackingClassifier(\n",
    "            base_classifiers=[\n",
    "                LogisticRegression(),\n",
    "                RandomForestClassifier(),\n",
    "            ],\n",
    "            meta_classifier=GradientBoostingClassifier(),\n",
    "        )\n",
    "    ],\n",
    "    meta_classifier=LogisticRegression(),\n",
    "    base_k_fold=5,#基分类器分拆份数,force_cv=True时生效，\n",
    "    meta_k_fold=5,#元分类器分拆份数,force_cv=True时生效，\n",
    ")\n",
    "classifier.build_model()\n",
    "classifier.fit(train_x=X_train, train_y=y_train)\n",
    "p_test = classifier.predict(X_test)\n",
    "print(f1_score(y_test, p_test, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 四.模型保存与加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存\n",
    "classifier.save_model('./classifier_model/stacking.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载\n",
    "new_classifier=Classifier.load_model('./classifier_model/stacking.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9582916621008432\n"
     ]
    }
   ],
   "source": [
    "p_test = new_classifier.predict(X_test)\n",
    "print(f1_score(y_test, p_test, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 五.自定义分类器\n",
    "这里使用Keras实现MLP来演示，由于Keras不是Sklearn风格的api，所以需要继承Classifier类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation\n",
    "class SimpleMLPClassifer(Classifier):\n",
    "    def __init__(self, train_params=None):\n",
    "        \"\"\"\n",
    "        :param train_params:\n",
    "        \"\"\"\n",
    "        Classifier.__init__(self, train_params)\n",
    "        self._check_params()\n",
    "\n",
    "    def _check_params(self):\n",
    "        if 'input_num' not in self.train_params:\n",
    "            raise RuntimeError('no input_num param in train_params!')\n",
    "        if 'class_num' not in self.train_params:\n",
    "            raise RuntimeError('no class_num param in train_params!')\n",
    "        if 'batch_size' not in self.train_params:\n",
    "            self.train_params['batch_size'] = 64\n",
    "        if 'epochs' not in self.train_params:\n",
    "            self.train_params['epochs'] = 5\n",
    "        if 'shuffle' not in self.train_params:\n",
    "            self.train_params['shuffle'] = True\n",
    "        if 'validation_split' not in self.train_params:\n",
    "            self.train_params['validation_split'] = 0.05\n",
    "\n",
    "    def build_model(self):\n",
    "        self.classifier_model = Sequential()\n",
    "        self.classifier_model.add(Dense(512, input_shape=(self.train_params['input_num'],)))\n",
    "        self.classifier_model.add(Activation('relu'))\n",
    "        self.classifier_model.add(Dropout(0.5))\n",
    "        self.classifier_model.add(Dense(self.train_params['class_num']))\n",
    "        self.classifier_model.add(Activation('softmax'))\n",
    "        self.classifier_model.compile(loss='categorical_crossentropy',\n",
    "                                      optimizer='adam',\n",
    "                                      metrics=['accuracy'])\n",
    "\n",
    "    def fit(self, train_x, train_y):\n",
    "        self.classifier_model.fit(x=train_x, y=utils.to_categorical(train_y, self.train_params['class_num']),\n",
    "                                  batch_size=self.train_params['batch_size'], epochs=self.train_params['epochs'],\n",
    "                                  validation_split=self.train_params['validation_split'],\n",
    "                                  shuffle=self.train_params['shuffle'],\n",
    "                                  verbose=False)\n",
    "\n",
    "    def predict_categorical(self, test_x):\n",
    "        categorical_labels = self.classifier_model.predict(test_x, batch_size=test_x.shape[0])\n",
    "        new_categorical_result = np.zeros(shape=categorical_labels.shape)\n",
    "        for index in range(0, len(categorical_labels)):\n",
    "            categorical_label = categorical_labels[index].tolist()\n",
    "            maxvalue_index = categorical_label.index(max(categorical_label))\n",
    "            new_categorical_result[index][maxvalue_index] = 1\n",
    "        return new_categorical_result\n",
    "\n",
    "    def predict(self, test_x):\n",
    "        p_categorical_probas = self.predict_categorical_proba(test_x)\n",
    "        result = []\n",
    "        for categorical_proba in p_categorical_probas:\n",
    "            categorical_proba = categorical_proba.tolist()\n",
    "            result.append(categorical_proba.index(max(categorical_proba)))\n",
    "        return np.asarray(result)\n",
    "\n",
    "    def predict_proba(self, test_x):\n",
    "        return self.classifier_model.predict_proba(test_x, batch_size=test_x.shape[0])\n",
    "\n",
    "    def predict_categorical_proba(self, test_x):\n",
    "        probas = self.classifier_model.predict_proba(test_x)\n",
    "        _, col = probas.shape\n",
    "        if col > 1:\n",
    "            return probas\n",
    "        else:\n",
    "            return np.asarray([[1 - proba, proba] for proba in probas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9496740862763298\n"
     ]
    }
   ],
   "source": [
    "#然后就可以嵌入到Stacking中了\n",
    "classifier = StackingClassifier(\n",
    "    base_classifiers=[\n",
    "        RandomForestClassifier(),\n",
    "        AdaBoostClassifier(),\n",
    "        BaggingClassifier(),\n",
    "        SVMClassifier(),\n",
    "        StackingClassifier(\n",
    "            base_classifiers=[\n",
    "                SimpleMLPClassifer(train_params={'input_num': 64, 'class_num': 10}),#放这儿\n",
    "                RandomForestClassifier(),\n",
    "            ],\n",
    "            meta_classifier=GradientBoostingClassifier(),\n",
    "        )\n",
    "    ],\n",
    "    meta_classifier=LogisticRegression()\n",
    ")\n",
    "classifier.build_model()\n",
    "classifier.fit(train_x=X_train, train_y=y_train)\n",
    "p_test = classifier.predict(X_test)\n",
    "print(f1_score(y_test, p_test, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 六.回归\n",
    "回归的操作与Classifier类似，不再赘述，下面列一下对应关系：  \n",
    "stacking_classifier->stacking_regressor   \n",
    "Classifier->Regressor  \n",
    "SklearnClassifier->SklearnRegressor  \n",
    "KFolds_Classifier_Training_Wrapper->KFolds_Regressor_Training_Wrapper  \n",
    "StackingClassifier->StackingRegressor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
